{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702fdf9b",
   "metadata": {},
   "source": [
    "# Zig-RiR Segmentation Training Notebook\n",
    "\n",
    "This notebook trains a Zig-RiR model for image segmentation using custom dataset structure:\n",
    "- train/images (.jpg)\n",
    "- train/masks (.png binary 0-255)\n",
    "- val/images (.jpg) \n",
    "- val/masks (.png binary 0-255)\n",
    "- test/images (.jpg) - for prediction only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef15250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9784fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class for your data structure\n",
    "class CustomSegmentationDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir=None, transform=None, crop_size=(512, 512), is_test=False):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.masks_dir = Path(masks_dir) if masks_dir else None\n",
    "        self.transform = transform\n",
    "        self.crop_size = crop_size\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        # Get all image files\n",
    "        self.image_files = sorted([f for f in self.images_dir.glob('*.jpg')])\n",
    "        \n",
    "        if not self.is_test:\n",
    "            # For train/val, check that masks exist\n",
    "            self.mask_files = []\n",
    "            for img_file in self.image_files:\n",
    "                mask_file = self.masks_dir / f\"{img_file.stem}.png\"\n",
    "                if mask_file.exists():\n",
    "                    self.mask_files.append(mask_file)\n",
    "                else:\n",
    "                    print(f\"Warning: No mask found for {img_file}\")\n",
    "            \n",
    "            assert len(self.image_files) == len(self.mask_files), \"Mismatch between images and masks\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_files[idx]\n",
    "        image = cv2.imread(str(img_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if not self.is_test:\n",
    "            # Load mask\n",
    "            mask_path = self.mask_files[idx]\n",
    "            mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "            # Convert to binary (0, 1)\n",
    "            mask = (mask > 127).astype(np.uint8)\n",
    "        else:\n",
    "            mask = None\n",
    "        \n",
    "        # Resize\n",
    "        image = cv2.resize(image, self.crop_size, interpolation=cv2.INTER_LINEAR)\n",
    "        if mask is not None:\n",
    "            mask = cv2.resize(mask, self.crop_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = torch.from_numpy(mask).long()\n",
    "            return {'image': image, 'label': mask, 'filename': img_path.name}\n",
    "        else:\n",
    "            return {'image': image, 'filename': img_path.name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0cec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.data_root = \"./data\"  # Change this to your data root\n",
    "        self.crop_size = [512, 512]\n",
    "        self.nclass = 2  # Background and foreground\n",
    "        self.batch_size = 4\n",
    "        self.num_epochs = 50\n",
    "        self.learning_rate = 0.0003\n",
    "        self.weight_decay = 0.0001\n",
    "        self.save_dir = \"./checkpoints\"\n",
    "        self.results_dir = \"./results\"\n",
    "        self.channels = [64, 128, 256, 512]\n",
    "        \n",
    "        # Create directories\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        os.makedirs(self.results_dir, exist_ok=True)\n",
    "\n",
    "config = Config()\n",
    "print(\"Configuration loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b24524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and modify the model from your existing files\n",
    "try:\n",
    "    from Zig_RiR2d import ZRiR\n",
    "    print(\"Successfully imported Zig-RiR model\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing Zig-RiR model: {e}\")\n",
    "    print(\"Please ensure all dependencies are installed and CUDA files are present\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"Model imported with CPU fallback\")\n",
    "    from Zig_RiR2d import ZRiR\n",
    "\n",
    "# Loss functions from your existing code\n",
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, weights=None, ignore_index=255):\n",
    "        super(CrossEntropyLoss, self).__init__()\n",
    "        if weights is not None:\n",
    "            weights = torch.from_numpy(np.array(weights)).float().to(device)\n",
    "        self.ce_loss = nn.CrossEntropyLoss(ignore_index=ignore_index, weight=weights)\n",
    "\n",
    "    def forward(self, prediction, label):\n",
    "        loss = self.ce_loss(prediction, label)\n",
    "        return loss\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "    def _one_hot_encoder(self, input_tensor):\n",
    "        tensor_list = []\n",
    "        for i in range(self.n_classes):\n",
    "            temp_prob = input_tensor == i * torch.ones_like(input_tensor)\n",
    "            temp_prob = torch.unsqueeze(temp_prob, 1)\n",
    "            tensor_list.append(temp_prob)\n",
    "        output_tensor = torch.cat(tensor_list, dim=1)\n",
    "        return output_tensor.float()\n",
    "\n",
    "    def _dice_loss(self, score, target):\n",
    "        target = target.float()\n",
    "        smooth = 1e-5\n",
    "        intersect = torch.sum(score * target)\n",
    "        y_sum = torch.sum(target * target)\n",
    "        z_sum = torch.sum(score * score)\n",
    "        loss = (2 * intersect + smooth) / (z_sum + y_sum + smooth)\n",
    "        loss = 1 - loss\n",
    "        return loss\n",
    "\n",
    "    def forward(self, inputs, target, weight=None, softmax=True):\n",
    "        if softmax:\n",
    "            inputs = torch.softmax(inputs, dim=1)\n",
    "        target = self._one_hot_encoder(target)\n",
    "        if weight is None:\n",
    "            weight = [1] * self.n_classes\n",
    "        assert inputs.size() == target.size(), 'predict & target shape do not match'\n",
    "        class_wise_dice = []\n",
    "        loss = 0.0\n",
    "        for i in range(0, self.n_classes):\n",
    "            dice = self._dice_loss(inputs[:, i], target[:, i])\n",
    "            class_wise_dice.append(1.0 - dice.item())\n",
    "            loss += dice * weight[i]\n",
    "        return loss / self.n_classes\n",
    "\n",
    "# Combined loss\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.ce_loss = CrossEntropyLoss()\n",
    "        self.dice_loss = DiceLoss(n_classes)\n",
    "    \n",
    "    def forward(self, prediction, target):\n",
    "        ce = self.ce_loss(prediction, target)\n",
    "        dice = self.dice_loss(prediction, target)\n",
    "        return ce + dice\n",
    "\n",
    "print(\"Loss functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e481a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "def create_dataloaders(config):\n",
    "    # Training dataset\n",
    "    train_dataset = CustomSegmentationDataset(\n",
    "        images_dir=os.path.join(config.data_root, \"train/images\"),\n",
    "        masks_dir=os.path.join(config.data_root, \"train/masks\"),\n",
    "        crop_size=tuple(config.crop_size),\n",
    "        is_test=False\n",
    "    )\n",
    "    \n",
    "    # Validation dataset\n",
    "    val_dataset = CustomSegmentationDataset(\n",
    "        images_dir=os.path.join(config.data_root, \"val/images\"),\n",
    "        masks_dir=os.path.join(config.data_root, \"val/masks\"),\n",
    "        crop_size=tuple(config.crop_size),\n",
    "        is_test=False\n",
    "    )\n",
    "    \n",
    "    # Test dataset\n",
    "    test_dataset = CustomSegmentationDataset(\n",
    "        images_dir=os.path.join(config.data_root, \"test/images\"),\n",
    "        crop_size=tuple(config.crop_size),\n",
    "        is_test=True\n",
    "    )\n",
    "    \n",
    "    # Dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=1, \n",
    "        shuffle=False, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=1, \n",
    "        shuffle=False, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset\n",
    "\n",
    "train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset = create_dataloaders(config)\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf2aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ZRiR(\n",
    "    channels=config.channels,\n",
    "    num_classes=config.nclass,\n",
    "    img_size=config.crop_size[0],\n",
    "    in_chans=3\n",
    ").to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = CombinedLoss(config.nclass)\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=config.weight_decay,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-08\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.num_epochs)\n",
    "\n",
    "print(\"Model initialized\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics (from your existing code)\n",
    "class Evaluator:\n",
    "    def __init__(self):\n",
    "        self.MAE = []\n",
    "        self.Recall = []\n",
    "        self.Precision = []\n",
    "        self.Accuracy = []\n",
    "        self.Dice = []\n",
    "        self.IoU = []\n",
    "\n",
    "    def evaluate(self, pred, gt):\n",
    "        pred_binary = (pred >= 0.5).float()\n",
    "        pred_binary_inverse = (pred_binary == 0).float()\n",
    "        gt_binary = (gt >= 0.5).float()\n",
    "        gt_binary_inverse = (gt_binary == 0).float()\n",
    "        \n",
    "        MAE = torch.abs(pred_binary - gt_binary).mean()\n",
    "        TP = pred_binary.mul(gt_binary).sum()\n",
    "        FP = pred_binary.mul(gt_binary_inverse).sum()\n",
    "        TN = pred_binary_inverse.mul(gt_binary_inverse).sum()\n",
    "        FN = pred_binary_inverse.mul(gt_binary).sum()\n",
    "        \n",
    "        if TP.item() == 0:\n",
    "            TP = torch.tensor(1.0).to(pred.device)\n",
    "            \n",
    "        Recall = TP / (TP + FN + 1e-8)\n",
    "        Precision = TP / (TP + FP + 1e-8)\n",
    "        Dice = 2 * Precision * Recall / (Precision + Recall + 1e-8)\n",
    "        Accuracy = (TP + TN) / (TP + FP + FN + TN + 1e-8)\n",
    "        IoU = TP / (TP + FP + FN + 1e-8)\n",
    "\n",
    "        return (MAE.cpu().numpy(), Recall.cpu().numpy(), \n",
    "                Precision.cpu().numpy(), Accuracy.cpu().numpy(), \n",
    "                Dice.cpu().numpy(), IoU.cpu().numpy())\n",
    "\n",
    "    def update(self, pred, gt):\n",
    "        mae, recall, precision, accuracy, dice, iou = self.evaluate(pred, gt)\n",
    "        self.MAE.append(mae)\n",
    "        self.Recall.append(recall)\n",
    "        self.Precision.append(precision)\n",
    "        self.Accuracy.append(accuracy)\n",
    "        self.Dice.append(dice)\n",
    "        self.IoU.append(iou)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        return {\n",
    "            'MAE': np.mean(self.MAE) * 100,\n",
    "            'Recall': np.mean(self.Recall) * 100,\n",
    "            'Precision': np.mean(self.Precision) * 100,\n",
    "            'Accuracy': np.mean(self.Accuracy) * 100,\n",
    "            'Dice': np.mean(self.Dice) * 100,\n",
    "            'IoU': np.mean(self.IoU) * 100\n",
    "        }\n",
    "\n",
    "print(\"Evaluator class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_batches = len(train_loader)\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config.num_epochs}')\n",
    "    \n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Avg Loss': f'{total_loss/(batch_idx+1):.4f}',\n",
    "            'LR': f'{optimizer.param_groups[0][\"lr\"]:.6f}'\n",
    "        })\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "print(\"Training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40368007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    evaluator = Evaluator()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc='Validating'):\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Get predictions\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            pred_binary = predictions.float()\n",
    "            gt_binary = labels.float()\n",
    "            \n",
    "            # Update evaluator\n",
    "            evaluator.update(pred_binary, gt_binary)\n",
    "    \n",
    "    metrics = evaluator.get_metrics()\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    \n",
    "    return avg_loss, metrics\n",
    "\n",
    "print(\"Validation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88651cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_dice = 0.0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_metrics_history = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    # Training\n",
    "    train_loss = train_one_epoch(model, train_loader, criterion, optimizer, epoch)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_metrics = validate(model, val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_metrics_history.append(val_metrics)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nEpoch {epoch+1}/{config.num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Val Metrics: Dice: {val_metrics['Dice']:.2f}, IoU: {val_metrics['IoU']:.2f}, Acc: {val_metrics['Accuracy']:.2f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_metrics['Dice'] > best_dice:\n",
    "        best_dice = val_metrics['Dice']\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_dice': best_dice,\n",
    "            'val_metrics': val_metrics\n",
    "        }, os.path.join(config.save_dir, 'best_model.pth'))\n",
    "        print(f\"New best model saved with Dice: {best_dice:.2f}\")\n",
    "    \n",
    "    # Save checkpoint every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_metrics': val_metrics\n",
    "        }, os.path.join(config.save_dir, f'checkpoint_epoch_{epoch+1}.pth'))\n",
    "\n",
    "print(f\"\\nTraining completed! Best Dice: {best_dice:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90239415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Loss curves\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Dice score\n",
    "plt.subplot(1, 3, 2)\n",
    "dice_scores = [m['Dice'] for m in val_metrics_history]\n",
    "plt.plot(dice_scores, label='Dice Score', color='green')\n",
    "plt.title('Validation Dice Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Dice (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# IoU score\n",
    "plt.subplot(1, 3, 3)\n",
    "iou_scores = [m['IoU'] for m in val_metrics_history]\n",
    "plt.plot(iou_scores, label='IoU Score', color='orange')\n",
    "plt.title('Validation IoU Score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('IoU (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config.results_dir, 'training_curves.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for prediction\n",
    "def load_best_model():\n",
    "    model = ZRiR(\n",
    "        channels=config.channels,\n",
    "        num_classes=config.nclass,\n",
    "        img_size=config.crop_size[0],\n",
    "        in_chans=3\n",
    "    ).to(device)\n",
    "    \n",
    "    checkpoint = torch.load(os.path.join(config.save_dir, 'best_model.pth'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f\"Loaded best model with Dice: {checkpoint['best_dice']:.2f}\")\n",
    "    return model\n",
    "\n",
    "best_model = load_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef35408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict_test_set(model, test_loader, output_dir):\n",
    "    model.eval()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Predicting on {len(test_dataset)} test images...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc='Predicting'):\n",
    "            images = batch['image'].to(device)\n",
    "            filenames = batch['filename']\n",
    "            \n",
    "            # Get predictions\n",
    "            outputs = model(images)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # Convert to numpy and save\n",
    "            for i, filename in enumerate(filenames):\n",
    "                pred_mask = predictions[i].cpu().numpy().astype(np.uint8) * 255\n",
    "                \n",
    "                # Save prediction\n",
    "                output_path = os.path.join(output_dir, f\"{Path(filename).stem}_pred.png\")\n",
    "                cv2.imwrite(output_path, pred_mask)\n",
    "    \n",
    "    print(f\"Predictions saved to {output_dir}\")\n",
    "\n",
    "# Create predictions directory and run prediction\n",
    "predictions_dir = os.path.join(config.results_dir, \"test_predictions\")\n",
    "predict_test_set(best_model, test_loader, predictions_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd21601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some predictions\n",
    "def visualize_predictions(test_loader, model, num_samples=5):\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(15, 6))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "                \n",
    "            images = batch['image'].to(device)\n",
    "            filename = batch['filename'][0]\n",
    "            \n",
    "            # Get prediction\n",
    "            outputs = model(images)\n",
    "            prediction = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            # Convert to numpy for visualization\n",
    "            image_np = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "            pred_np = prediction[0].cpu().numpy()\n",
    "            \n",
    "            # Plot original image\n",
    "            axes[0, i].imshow(image_np)\n",
    "            axes[0, i].set_title(f'Input: {filename}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Plot prediction\n",
    "            axes[1, i].imshow(pred_np, cmap='gray')\n",
    "            axes[1, i].set_title('Prediction')\n",
    "            axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(config.results_dir, 'sample_predictions.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(test_loader, best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0582e1af",
   "metadata": {},
   "source": [
    "# Training Summary\n",
    "\n",
    "The notebook has completed the following steps:\n",
    "1. ✅ Loaded and preprocessed your custom dataset structure\n",
    "2. ✅ Trained the Zig-RiR model with combined Dice + CrossEntropy loss\n",
    "3. ✅ Validated the model and tracked metrics\n",
    "4. ✅ Saved the best model based on Dice score\n",
    "5. ✅ Generated predictions on test set\n",
    "6. ✅ Created visualizations of training progress and sample predictions\n",
    "\n",
    "## Output Files:\n",
    "- **Checkpoints**: `./checkpoints/best_model.pth` \n",
    "- **Predictions**: `./results/test_predictions/` (contains prediction masks)\n",
    "- **Visualizations**: `./results/training_curves.png`, `./results/sample_predictions.png`\n",
    "\n",
    "## Next Steps:\n",
    "- Adjust hyperparameters if needed\n",
    "- Experiment with data augmentation\n",
    "- Try different loss functions or optimizers\n",
    "- Evaluate on additional metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
